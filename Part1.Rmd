---
title: "Part 1"
author: "Karol Szwed"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
library(knitr)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(cache = TRUE)

library(ggplot2)
library(reshape2)
library(caret)
library(dplyr)
library(glmnet)
```

## Eksploracja danych

```{r wczytywanie danych}
X_test <- read.csv("X_test.csv")
X_train <- read.csv("X_train.csv")
Y_train <- read.csv("y_train.csv")
```


```{r podpunkt a - ekspoatacja danych}
print("Dane treningowe - RNA")
print(dim(X_train))

print("Dane treningowe - białko powierzchniowe")
print(dim(Y_train))

print("Dane testowe")
print(dim(X_test))

# Typ zmiennych - wszystkie powinny być typu 'double'
print(all(sapply(X_test, is.double)))
print(all(sapply(X_train, is.double)))
print(all(sapply(Y_train, is.double)))

# Sprawdzenie czy są braki danych
print(any(sapply(X_test, is.na)))
print(any(sapply(X_train, is.na)))
print(any(sapply(Y_train, is.na)))
```

```{r podpunkt b - rozkład zmiennej objaśnianej}
# Badamy rozkład zmiennej objaśnianej (dane 'Y_train')
summary(Y_train)

# Histogram
ggplot(data = Y_train, aes(x = CD36)) + geom_histogram(color="black", fill="white")

# Wykres kwantylowy
ggplot(data = Y_train) + geom_qq(aes(sample = CD36), size=1.5, color="red")

```


```{r podpunkt c - korelacja zmiennych}
# Korelacja zmiennych
# Wybieramy 250 zmiennych o największej korelacji z zmienną objaśnianą
skorelowane <- apply(X_train, 2, function (x) cor(x, Y_train))
X_wybrane <- X_train[, order(skorelowane, decreasing = T)[1:250]]

# Macierz korelacji
cor_matrix <- cor(X_wybrane)
cor_relations <- melt(cor_matrix)

# Ilustrujemy wynik za pomocą mapy ciepła
install.packages("viridis")
library(viridis)
Var.heatmap <- ggplot(data = cor_relations, mapping = aes(x = Var1,
                                                          y = Var2,
                                                          fill = value)) +
  geom_tile() + scale_fill_viridis(discrete=FALSE) +
  theme(axis.text.x = element_blank(), axis.text.y = element_blank()) +
  coord_fixed()
print(Var.heatmap)
```

## Testy statystyczne


```{r Punkt 2 - WIP}
ggplot(data = Y_train) +
  geom_qq(aes(sample = CD36), size=1.5, color = "red") +
  geom_qq_line(aes(sample = CD36))


ks.test(Y_train, "pnorm") # Test Kolmogorova-Smiernov'a


# Wybieramy zmienne najbardziej skorelowane
correlations <- apply(X_train, 2, function (x) cor(x, Y_train))
most_correlated <- X_train[,order(correlations, decreasing = T)[1]]

# Test statystyczny hipotezy zgodności z rozkładem
ggplot() + aes(x = most_correlated) + 
  geom_histogram(binwidth = 0.1, color="blue", fill="white")

# Normalizacja danych
most_normalized <- (most_correlated - mean(most_correlated)) / sd(most_correlated)

ks.test(most_normalized, "pnorm") # Is it normal? It should be, except this pike in 0
most_cleared <- most_normalized[most_correlated > 0.2]
ks.test(most_cleared, "pnorm")



```

## ElasticNet

TODO - Opis modelu ElasticNet (podpunkt _a)_)

```{r - tworzenie foldów do walidacji krzyżowej}
# Tworzy 'k' foldów do walidacji krzyżowej
create_folds <- function(data, k = 10) {
  set.seed(123)  # Ustalamy ziarno dla powtarzalności wyników
  n <- nrow(data)
  indices <- sample(1:n)
  folds <- cut(indices, breaks = k, labels = FALSE)

  result <- lapply(1:k, function(x) {
    test_idx <- which(folds == x)
    train_idx <- setdiff(1:n, test_idx)
    list(train = train_idx, test = test_idx)
  })

  return(result)
}
```


```{r - tuning hiperparametrów}

# Tworzymy foldy do walidacji krzyżowej
folds <- create_folds(X_train, k = 5)

# Tworzymy siatkę hiperparametrów
alphas <- c(0, 0.1, 0.5, 0.9, 1)  # 0 dla Ridge, 1 dla Lasso
lambdas <- 10^seq(2, -2, length = 10)  # od 100 do 0.01

# Pusta do lista do zapisania wyników CV
results <- list()

# Przechodzimy przez wszystkie kombinacje hiperparametrów
for (alpha in alphas) {
  for (lambda in lambdas) {
    fold_metrics <- numeric(length(folds))
    
    for (i in seq_along(folds)) {
      fold <- folds[[i]]
      
      # Indeksy treningowe i testowe
      train_indices <- fold$train
      test_indices <- fold$test
      
      # Dzielimy dane
      X_train_fold <- as.matrix(X_train[train_indices, , drop = FALSE])
      Y_train_fold <- Y_train[train_indices, ]
      X_test_fold <- as.matrix(X_train[test_indices, , drop = FALSE])
      Y_test_fold <- Y_train[test_indices, ]
      
      # Tworzymy model ElasticNet
      model <- glmnet(X_train_fold, Y_train_fold, alpha = alpha, lambda = lambda)
      
      # Predykcje dla zbioru testowego
      predictions <- predict(model, s = lambda, newx = X_test_fold)
      
      # MSE dla foldu testowego
      fold_metrics[i] <- mean((Y_test_fold - predictions)^2)
    }
    
    # Zapisujemy wynik
    results[[paste("Alpha", alpha, "Lambda", lambda)]] <- mean(fold_metrics)
  }
}

print(results)

# Wybieramy najlepsze hiperparametry
best_params <- which.min(unlist(results))
results[best_params]




```


