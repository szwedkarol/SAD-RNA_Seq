---
title: "Part 1"
author: "Karol Szwed"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
library(knitr)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(cache = TRUE)

library(ggplot2)
library(reshape2)
library(caret)
library(dplyr)
library(glmnet)
```

## Eksploracja danych

```{r wczytywanie danych}
X_test <- read.csv("X_test.csv")
X_train <- read.csv("X_train.csv")
Y_train <- read.csv("y_train.csv")
```

### A) Rozmiar danych i typ zmiennych

Widzimy, że dane treningowe składają się z $6800$ obserwacji i $9000$ zmiennych objaśniających. Dane testowe składają się z $1200$ obserwacji i $9000$ zmiennych objaśniających. Zmienna objaśniana (białko $CD36$) jest jednowymiarowa. Wszystkie zmienne są typu 'double', co jest zgodne z oczekiwaniami. Tym samym nie dokonujemy konwersji typów zmiennych. Nie ma braków danych.

```{r podstawowa eksploracja danych}
print("Dane treningowe - RNA")
print(dim(X_train))

print("Dane treningowe - białko powierzchniowe")
print(dim(Y_train))

print("Dane testowe - RNA")
print(dim(X_test))
```

```{r typ zmiennych i braki danych}
# Typ zmiennych - wszystkie powinny być typu 'double'
print(all(sapply(X_test, is.double)))
print(all(sapply(X_train, is.double)))
print(all(sapply(Y_train, is.double)))

# Sprawdzenie czy są braki danych
print(any(sapply(X_test, is.na)))
print(any(sapply(X_train, is.na)))
print(any(sapply(Y_train, is.na)))
```

### B) Rozkład zmiennej objaśnianej

Zmienna objaśniana (białko $CD36$) jest zmienną ciągłą. Na histogramie widać, że dla wartości mniejszych od $0.5$ występuje duża liczba obserwacji. Wykres kwantylowy pokazuje, że rozkład zmiennej objaśnianej jest zbliżony do rozkładu normalnego, z wyjątkiem wartości skrajnie małych.

```{r podpunkt b - rozkład zmiennej objaśnianej}
# Badamy rozkład zmiennej objaśnianej (dane 'Y_train')
summary(Y_train)

# Histogram
ggplot(data = Y_train, aes(x = CD36)) + geom_histogram(color="black", fill="white")

# Wykres kwantylowy
ggplot(data = Y_train) + geom_qq(aes(sample = CD36), size=1.5, color="red")

```
### C) Korelacja zmiennych

Obrazujemy korelację zmiennych na mapie ciepła. Wybieramy $250$ zmiennych o największej korelacji z zmienną objaśnianą. Widać, że niektóre zmienne są ze sobą mocno skorelowane.

```{r podpunkt c - korelacja zmiennych}
# Korelacja zmiennych
# Wybieramy 250 zmiennych o największej korelacji z zmienną objaśnianą
correlated <- apply(X_train, 2, function (x) cor(x, Y_train))
X_high_cor <- X_train[, order(correlated, decreasing = T)[1:250]]

# Macierz korelacji
cor_matrix <- cor(X_high_cor)
cor_relations <- melt(cor_matrix)

# Ilustrujemy wynik za pomocą mapy ciepła
library(viridis)
Var.heatmap <- ggplot(data = cor_relations, mapping = aes(x = Var1,
                                                          y = Var2,
                                                          fill = value)) +
  geom_tile() + scale_fill_viridis(discrete=FALSE) +
  theme(axis.text.x = element_blank(), axis.text.y = element_blank()) +
  coord_fixed()
print(Var.heatmap)
```

## Testy statystyczne


```{r Punkt 2 - WIP}
ggplot(data = Y_train) +
  geom_qq(aes(sample = CD36), size=1.5, color = "red") +
  geom_qq_line(aes(sample = CD36))


ks.test(Y_train, "pnorm") # Test Kolmogorova-Smiernov'a


# Wybieramy zmienne najbardziej skorelowane
correlations <- apply(X_train, 2, function (x) cor(x, Y_train))
most_correlated <- X_train[,order(correlations, decreasing = T)[1]]

# Test statystyczny hipotezy zgodności z rozkładem
ggplot() + aes(x = most_correlated) + 
  geom_histogram(binwidth = 0.1, color="blue", fill="white")

# Normalizacja danych
most_normalized <- (most_correlated - mean(most_correlated)) / sd(most_correlated)

ks.test(most_normalized, "pnorm") # Is it normal? It should be, except this pike in 0
most_cleared <- most_normalized[most_correlated > 0.2]
ks.test(most_cleared, "pnorm")
```

## ElasticNet

### A) Opis modelu ElasticNet

_ElasticNet_ jest metodą regularyzowanej regresji, która liniowo łączy w sobie dwa rodzaje regularyzacji: $\ell_1$ (_LASSO_) i $\ell_2$ (_Ridge_). Regularyzacja $\ell_1$ redukuje współczynniki modelu do zera, co pozwala na selekcję zmiennych. Regularyzacja $\ell_2$ z kolei zmniejsza wartości współczynników, ale nie redukuje ich do zera. Dzięki temu model _ElasticNet_ łączy w sobie zalety obu metod, co pozwala na selekcję zmiennych oraz zmniejszenie wariancji modelu.

Model ten jest szczególnie przydatny przy dużych zbiorach danych, które zawierają wiele zmiennych współliniowych lub kiedy liczba zmiennych jest większa od liczby obserwacji. W naszym przypadku, gdzie mamy do czynienia z $9000$ zmiennymi i $6800$ obserwacjami, model _ElasticNet_ może okazać się bardzo przydatny.

Model _ElasticNet_ optymalizuje parametry regresji $\beta$. Te współczynniki obrazują zależność między zmiennymi objaśniającymi a zmienną objaśnianą.
Model ten minimalizuje następującą funkcję straty:

$$ \underset{\beta}{\min} \left\{ \frac{1}{2n} \sum_{i=1}^n (y_i - X_i \beta)^2 + \lambda \left( \alpha \sum_{j=1}^p |\beta_j| + \frac{1}{2} (1 - \alpha) \sum_{j=1}^p \beta_j^2 \right) \right\} $$

gdzie:
- $n$ - liczba obserwacji.
- $y_i$ - zmienna objaśniana.
- $X_i$ - wektor zmiennych objaśniających.
- $\beta$ - wektor współczynników.
- $\lambda$ - parametr regularyzacji.
- $\alpha$ - parametr mieszający, gdzie $ 0 \leq \alpha \leq 1 $.

Dla $\alpha = 0$, _ElasticNet_ odpowiada regresji grzbietowej, a dla $\alpha = 1$, model odpowiada regresji _LASSO_.

### B) Tuning hiperparametrów

Definiujemy funkcję, która tworzy zadaną liczbę foldów w zbiorze danych przekazanym jako argument.

```{r - tworzenie foldów do walidacji krzyżowej}
# Tworzy 'k' foldów do walidacji krzyżowej
create_folds <- function(data, k = 10) {
  set.seed(123)  # Ustalamy ziarno dla powtarzalności wyników
  n <- nrow(data)
  indices <- sample(1:n)
  folds <- cut(indices, breaks = k, labels = FALSE)

  result <- lapply(1:k, function(x) {
    test_idx <- which(folds == x)
    train_idx <- setdiff(1:n, test_idx)
    list(train = train_idx, test = test_idx)
  })

  # Zwracamy listę wektorów indeksów
  return(result)
}
```

Chcemy zminimalizować prawdopodobieństwo, że w danym foldzie duża część wartości $y_i$ jest równa $0$ lub jest blisko zera. Stąd dzielimy dane na $5$ foldów.

```{r - tuning hiperparametrów}

# Foldy do walidacji krzyżowej
folds <- create_folds(X_train, k = 5)

# Siatka hiperparametrów
alphas <- c(0, 0.1, 0.5, 0.9, 1)  # 0 dla Ridge, 1 dla Lasso
lambdas <- 10^seq(2, -2, length = 10)  # od 100 do 0.01

# Pusta lista do zapisania wyników CV
results <- list()

# Przechodzimy przez wszystkie kombinacje hiperparametrów
for (alpha in alphas) {
  for (lambda in lambdas) {
    fold_metrics <- numeric(length(folds))
    
    for (i in seq_along(folds)) {
      fold <- folds[[i]]
      
      # Indeksy treningowe i testowe
      train_indices <- fold$train
      test_indices <- fold$test
      
      # Dzielimy dane
      X_train_fold <- as.matrix(X_train[train_indices, , drop = FALSE])
      Y_train_fold <- Y_train[train_indices, ]
      X_test_fold <- as.matrix(X_train[test_indices, , drop = FALSE])
      Y_test_fold <- Y_train[test_indices, ]
      
      # Tworzymy model ElasticNet
      model <- glmnet(X_train_fold, Y_train_fold, alpha = alpha, lambda = lambda)
      
      # Predykcje dla zbioru testowego
      predictions <- predict(model, s = lambda, newx = X_test_fold)
      
      # MSE dla foldu testowego
      fold_metrics[i] <- mean((Y_test_fold - predictions)^2)
    }
    
    # Zapisujemy wynik
    results[[paste("Alpha", alpha, "Lambda", lambda)]] <- mean(fold_metrics)
  }
}

print(results)

# Wybieramy najlepsze hiperparametry
best_params <- which.min(unlist(results))
results[best_params]

```


